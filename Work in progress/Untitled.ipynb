{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pybaseball\n",
      "Requirement already satisfied: numpy>=1.13.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pybaseball) (1.14.3)\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pybaseball) (4.6.0)\n",
      "Requirement already satisfied: pandas>=0.20.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pybaseball) (0.24.2)\n",
      "Requirement already satisfied: lxml>=4.2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pybaseball) (4.2.1)\n",
      "Requirement already satisfied: requests>=2.18.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pybaseball) (2.20.0)\n",
      "Requirement already satisfied: pytz>=2011k in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas>=0.20.2->pybaseball) (2018.4)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas>=0.20.2->pybaseball) (2.7.3)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests>=2.18.1->pybaseball) (2.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests>=2.18.1->pybaseball) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests>=2.18.1->pybaseball) (2019.6.16)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests>=2.18.1->pybaseball) (1.23)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from python-dateutil>=2.5.0->pandas>=0.20.2->pybaseball) (1.11.0)\n",
      "Installing collected packages: pybaseball\n",
      "Successfully installed pybaseball-1.0.8\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pybaseball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pybaseball import statcast\n",
    "import random\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Season_cleaner:\n",
    "    \"\"\"\n",
    "    Cleans a season dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    def __init__(self, dataframe):\n",
    "        \n",
    "        self.df = dataframe\n",
    "        \n",
    "        # Features to drop\n",
    "        self.drop_columns = [\n",
    "            'spin_dir',\n",
    "            'spin_rate_deprecated',\n",
    "            'break_angle_deprecated',\n",
    "            'break_length_deprecated',\n",
    "            'game_type',\n",
    "            'tfs_deprecated',\n",
    "            'tfs_zulu_deprecated',\n",
    "            'umpire'\n",
    "        ]\n",
    "        \n",
    "        # List fo unique pitcher ID's\n",
    "        self.pitchers = self.df['pitcher'].unique().tolist()\n",
    "    \n",
    "    \n",
    "    def drop_features(self):\n",
    "        \"\"\"\n",
    "        Drops depriciated features\n",
    "        \"\"\"\n",
    "        self.df = self.df.drop(columns = self.drop_columns)\n",
    "        \n",
    "        \n",
    "    def drop_instances(self):\n",
    "        \"\"\"\n",
    "        Drops useless instances\n",
    "        \"\"\"\n",
    "        self.df = self.df.dropna(axis = 0, how = 'all')\n",
    "\n",
    "                \n",
    "    def fielding_alignment_typecast(self):\n",
    "        \"\"\"\n",
    "        Forces the object type onto the fielding allignment columns\n",
    "        \"\"\"\n",
    "        self.df['if_fielding_alignment'] = self.df['if_fielding_alignment'].astype(object)\n",
    "        self.df['of_fielding_alignment'] = self.df['of_fielding_alignment'].astype(object)\n",
    "\n",
    "        \n",
    "    def chronological_sort(self):\n",
    "        \"\"\"\n",
    "        Sort pitches chronologically\n",
    "        \"\"\"\n",
    "        self.df = self.df.sort_values(by = [\n",
    "            'game_date',\n",
    "            'game_pk',\n",
    "            'at_bat_number',\n",
    "            'pitch_number'\n",
    "            ])\n",
    "\n",
    "\n",
    "    def pitch_type(self):\n",
    "        \"\"\"\n",
    "        Feature Name: pitch_type\n",
    "        Feature Description: The type of pitch derived from Statcast.\n",
    "        Issue: Feature is supposed to contain a 2 character string, but many values (265) are filled with long strings of numerical characters. Example: 160421_181540\n",
    "        Solution: Replace values longer than 2 characters in lengeth with np.NaN\n",
    "        \"\"\"\n",
    "\n",
    "        self.df['pitch_type'] = self.df.apply(\n",
    "            lambda row: np.NaN\\\n",
    "                if len(str(row['pitch_type'])) > 2\\\n",
    "                else row['pitch_type'], axis = 1)\n",
    "\n",
    "        \"\"\"\n",
    "        Issue: Many values of this feature are recorded as 'UN'\n",
    "        Solution: Replace value with np.NaN\n",
    "        \"\"\"\n",
    "        self.df['pitch_type'] = self.df['pitch_type'].replace({'UN':np.nan})\n",
    "\n",
    "        \"\"\"\n",
    "        Issue**: The pitch type feature is filled with NaN values\n",
    "        Solution: We will create a mapping of a pitchers id and his normalized pitch counts. Using these normalized values as weights we will select a random pitch type and fill the NaN value for that pitcher. We will use df.apply, but this could be time optomized by using series vectorization. \n",
    "        \"\"\"\n",
    "\n",
    "        # Populate mapping\n",
    "        pitcher_dict = {}\n",
    "        for pitcher in self.pitchers:\n",
    "\n",
    "            # Pitcher's prior pitch type probabilites\n",
    "            pitch_type_weights = self.df[self.df.pitcher == pitcher]\\\n",
    "                                    .pitch_type\\\n",
    "                                    .value_counts(normalize=True)\n",
    "\n",
    "            pitcher_dict[pitcher] = pitch_type_weights.to_dict()\n",
    "\n",
    "        # Fill nan values\n",
    "        pitcher_dict = pd.DataFrame(pitcher_dict).fillna(0).to_dict()\n",
    "\n",
    "\n",
    "        # Select replacement pitch type and fill NaN values\n",
    "\n",
    "        def pick_a_pitch(pitcher_id):\n",
    "            \"\"\" \n",
    "            Returns a random pitch type label\n",
    "            Uses pitchers prior pitch type probabilites as weights\n",
    "            \"\"\"\n",
    "\n",
    "            population = list(pitcher_dict[pitcher_id].keys())\n",
    "            weights = list(pitcher_dict[pitcher_id].values())\n",
    "\n",
    "            return random.choices(population, weights, k=1)[0]\n",
    "\n",
    "        # Iterate by instance, fill null values\n",
    "        self.df['pitch_type'] = self.df.apply(\n",
    "            lambda row: pick_a_pitch(row['pitcher']) \\\n",
    "                if pd.isnull(row['pitch_type']) \\\n",
    "                else row['pitch_type'], axis = 1)\n",
    "\n",
    "\n",
    "    def pitch_subtype(self):\n",
    "        \"\"\"\n",
    "        Creates a pitch_subtype feature\n",
    "        \"\"\"\n",
    "\n",
    "        pitch_type_map = {'FA':'fastball', 'FF':'fastball', 'FT':'fastball', 'FC':'fastball',\n",
    "                          'FS':'fastball', 'SI':'fastball', 'SF':'fastball', 'SL':'breaking',\n",
    "                          'CB':'breaking', 'CU':'breaking', 'SC':'breaking', 'KC':'breaking',\n",
    "                          'CH':'offspeed', 'KN':'offspeed', 'EP':'offspeed', 'FO':'breaking', \n",
    "                          'PO':'pitchout', 'IN':'pitchout'}\n",
    "\n",
    "        self.df['pitch_subtype'] = self.df['pitch_type']\n",
    "        self.df['pitch_type'] = self.df['pitch_type'].map(pitch_type_map)\n",
    "\n",
    "        \n",
    "    def count_status(self):\n",
    "        \"\"\"\n",
    "        Feature: count_status\n",
    "        Description: The ratio of balls and strikes for the current at bat\n",
    "        Issue: There are two existing features related to the count. We need to represent the count as a categorical feature.\n",
    "        Solution: Classifiy the pitchers position reguarding the count (Ahead, Behind, Neutral)\n",
    "        \"\"\"\n",
    "\n",
    "        self.df['balls'] = self.df['balls'].replace({4:3, 5:3})\n",
    "\n",
    "        self.df['count_status'] = self.df['balls'].astype('int').astype('str')\\\n",
    "                                  + self.df['strikes'].astype('int').astype('str')\n",
    "\n",
    "        count_status_mapping = {\n",
    "            '00':'neutral', '21':'neutral', '32':'neutral', '10':'behind',\n",
    "            '20':'behind', '30':'behind', '31':'behind', '01':'ahead',\n",
    "            '02':'ahead', '11':'ahead', '12':'ahead', '22':'ahead'\n",
    "        }\n",
    "\n",
    "        self.df['count_status'] = self.df['count_status'].map(count_status_mapping)\n",
    "\n",
    "\n",
    "    def score_differential(self):\n",
    "        \"\"\"\n",
    "        Feature: Score Differential\n",
    "        Description: The absolute value of the difference in home team score and away team score\n",
    "        \"\"\"\n",
    "\n",
    "        self.df['score_differential'] = abs(self.df['home_score'] - self.df['away_score'])\n",
    "\n",
    "\n",
    "    def bases_loaded(self):\n",
    "        \"\"\"\n",
    "        Feature**: Bases Loaded\n",
    "        Description: A binary indication of the bases being loaded or not\n",
    "        \"\"\"\n",
    "        self.df['on_1b'] = self.df['on_1b'] * 0 + 1\n",
    "        self.df['on_1b'] = self.df['on_1b'].fillna(0)\n",
    "        self.df['on_2b'] = self.df['on_2b'] * 0 + 1\n",
    "        self.df['on_2b'] = self.df['on_2b'].fillna(0)\n",
    "        self.df['on_3b'] = self.df['on_3b'] * 0 + 1\n",
    "        self.df['on_3b'] = self.df['on_3b'].fillna(0)\n",
    "\n",
    "        self.df['bases_loaded'] = self.df['on_1b'] + self.df['on_2b'] + self.df['on_3b']\n",
    "        self.df['bases_loaded'] = self.df['bases_loaded'].apply(lambda x: 1 if x == 3 else 0)\n",
    "\n",
    "\n",
    "    def batter_swung(self):\n",
    "        \"\"\"\n",
    "        Feature: swung\n",
    "        Description: Binary feature describing wheather or not the batter swung at the pitch or not\n",
    "        \"\"\"\n",
    "\n",
    "        swung = ['foul','hit_into_play','swinging_strike','hit_into_play_no_out',\n",
    "                 'hit_into_play_score','foul_tip','swinging_strike_blocked',\n",
    "                 'foul_bunt','missed_bunt']\n",
    "\n",
    "        self.df['batter_swung'] = self.df['description'].apply(lambda x: 1 if x in swung else 0)\n",
    "\n",
    "\n",
    "    def ball_position(self):\n",
    "        \"\"\"\n",
    "        Creates a feature describing where the pitch crosses the strikezone plane\n",
    "        \"\"\"\n",
    "        \n",
    "        self.df['ball_high'] = self.df['plate_z'] > self.df['sz_top']\n",
    "        self.df['ball_low'] = self.df['plate_z'] < self.df['sz_bot']\n",
    "        self.df['ball_left'] = self.df['plate_x'].apply(lambda x: x < -0.73)\n",
    "        self.df['ball_right'] = self.df['plate_x'].apply(lambda x: x > 0.73)\n",
    "\n",
    "\n",
    "    def in_strikezone(self):\n",
    "        \"\"\"\n",
    "        Binary feature representing wheather or not the pitch was in the strikezone\n",
    "        \"\"\"\n",
    "\n",
    "        self.df['in_strikezone'] = (self.df['ball_high'].astype(int)\n",
    "                                    + self.df['ball_low'].astype(int)\n",
    "                                    + self.df['ball_left'].astype(int)\n",
    "                                    + self.df['ball_right'].astype(int))\n",
    "\n",
    "        self.df['in_strikezone'] = self.df['in_strikezone'].apply(\n",
    "                                       lambda x: 0\n",
    "                                           if x > 0\n",
    "                                           else 1)\n",
    "\n",
    "\n",
    "    def chased(self):\n",
    "        \"\"\"\n",
    "        Binary feature representing wheather or not the batter chased the pitch\n",
    "        \"\"\"\n",
    "\n",
    "        self.df['chased'] = self.df['batter_swung'] - self.df['in_strikezone']\n",
    "        self.df['chased'] = self.df['chased'].apply(lambda x: 1 if x == 1 else 0)\n",
    "\n",
    "        \n",
    "    def clean(self):\n",
    "        print('Dropping features...')\n",
    "        self.drop_features()\n",
    "        print('Done!')\n",
    "        print('Dropping instances...')\n",
    "        self.drop_instances()\n",
    "        print('Done!')\n",
    "        print('Typecasting...')\n",
    "        self.fielding_alignment_typecast()\n",
    "        print('Done!')\n",
    "        print('Sorting pitches...')\n",
    "        self.chronological_sort()\n",
    "        print('Done!')\n",
    "        print('Cleaning pitch type...')\n",
    "        self.pitch_type()\n",
    "        print('Done!')\n",
    "        print('Creating pitch subtype...')\n",
    "        self.pitch_subtype()\n",
    "        print('Done!')\n",
    "        print('Creating count status...')\n",
    "        self.count_status()\n",
    "        print('Done!')\n",
    "        print('Creating score differential...')\n",
    "        self.score_differential()\n",
    "        print('Done!')\n",
    "        print('Creating bases loaded...')\n",
    "        self.bases_loaded()\n",
    "        print('Done!')\n",
    "        print('Creating batter swung...')\n",
    "        self.batter_swung()\n",
    "        print('Done!')\n",
    "        print('Creating ball position...')\n",
    "        self.ball_position()\n",
    "        print('Done!')\n",
    "        print('Creating strikezone...')\n",
    "        self.in_strikezone()\n",
    "        print('Done!')\n",
    "        print('Creating chased...')\n",
    "        self.chased()\n",
    "        print('Done!')\n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons = {'2010':{'start_date': '2010-04-04', 'end_date': '2010-04-10'},\n",
    "           #'2011':{'start_date': '2011-03-31', 'end_date': '2011-10-28'},\n",
    "           #'2012':{'start_date': '2012-03-28', 'end_date': '2012-10-28'},\n",
    "           #'2013':{'start_date': '2013-03-31', 'end_date': '2013-10-30'},\n",
    "           #'2014':{'start_date': '2014-03-22', 'end_date': '2014-10-29'},\n",
    "           #'2015':{'start_date': '2015-04-05', 'end_date': '2015-11-01'},\n",
    "           #'2016':{'start_date': '2016-04-03', 'end_date': '2016-11-02'},\n",
    "           #'2017':{'start_date': '2017-04-02', 'end_date': '2017-11-01'},\n",
    "           #'2018':{'start_date': '2018-03-29', 'end_date': '2018-10-28'},\n",
    "           #'2019':{'start_date': '2019-03-20', 'end_date': '2019-09-07'}\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_statcast_data(start_date, end_date, year):\n",
    "    \"\"\"\n",
    "    Date Format: YYYY-MM-DD\n",
    "    \"\"\"\n",
    "    df = statcast(start_dt = start_date, end_dt = end_date)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_and_export(df, year, f_path = \"season_pickles/\"):\n",
    "    \"\"\"\n",
    "    Pickle DataFrame\n",
    "    \"\"\"\n",
    "    df.to_pickle(path=(f_path + year + \".pkl\"\n",
    "    ),compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def pull_clean_and_pickle(start_date, end_date, year):\n",
    "        \"\"\"\n",
    "        Queries statcast, calls cleaning function, pickles season dataframes,\n",
    "        and writes to seasons directory\n",
    "        \"\"\"\n",
    "        df = pull_statcast_data(start_date, end_date, year)\n",
    "        df = Season_cleaner(df).clean()\n",
    "        compress_and_export(df, year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a large query, it may take a moment to complete\n",
      "Completed sub-query from 2010-04-04 to 2010-04-09\n",
      "Completed sub-query from 2010-04-10 to 2010-04-10\n"
     ]
    }
   ],
   "source": [
    "year = '2010'\n",
    "\n",
    "start_date = seasons[year]['start_date']\n",
    "end_date = seasons[year]['end_date']\n",
    "df = pull_statcast_data(start_date, end_date, year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping features...\n",
      "Done!\n",
      "Dropping instances...\n",
      "Done!\n",
      "Typecasting...\n",
      "Done!\n",
      "Sorting pitches...\n",
      "Done!\n",
      "Cleaning pitch type...\n",
      "Done!\n",
      "Creating pitch subtype...\n",
      "Done!\n",
      "Creating count status...\n",
      "Done!\n",
      "Creating score differential...\n",
      "Done!\n",
      "Creating bases loaded...\n",
      "Done!\n",
      "Creating batter swung...\n",
      "Done!\n",
      "Creating ball position...\n",
      "Done!\n",
      "Creating strikezone...\n",
      "Done!\n",
      "Creating chased...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "season = Season_cleaner(df)\n",
    "df = season.clean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a large query, it may take a moment to complete\n",
      "Completed sub-query from 2010-04-04 to 2010-04-09\n",
      "Completed sub-query from 2010-04-10 to 2010-04-10\n",
      "Dropping features...\n",
      "Done!\n",
      "Dropping instances...\n",
      "Done!\n",
      "Typecasting...\n",
      "Done!\n",
      "Sorting pitches...\n",
      "Done!\n",
      "Cleaning pitch type...\n",
      "Done!\n",
      "Creating pitch subtype...\n",
      "Done!\n",
      "Creating count status...\n",
      "Done!\n",
      "Creating score differential...\n",
      "Done!\n",
      "Creating bases loaded...\n",
      "Done!\n",
      "Creating batter swung...\n",
      "Done!\n",
      "Creating ball position...\n",
      "Done!\n",
      "Creating strikezone...\n",
      "Done!\n",
      "Creating chased...\n",
      "Done!\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'season_pickles/2010.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-97302bf7390f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mstart_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseasons\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'start_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mend_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseasons\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'end_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mpull_clean_and_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-49-c9905b3a90e6>\u001b[0m in \u001b[0;36mpull_clean_and_pickle\u001b[0;34m(start_date, end_date, year)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpull_statcast_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeason_cleaner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mcompress_and_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-48-9c13c25deb6a>\u001b[0m in \u001b[0;36mcompress_and_export\u001b[0;34m(df, year, f_path)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \"\"\"\n\u001b[1;32m      5\u001b[0m     df.to_pickle(path=(f_path + year + \".pkl\"\n\u001b[0;32m----> 6\u001b[0;31m     ),compression='zip')\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_pickle\u001b[0;34m(self, path, compression, protocol)\u001b[0m\n\u001b[1;32m   2591\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpickle\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2592\u001b[0m         return to_pickle(self, path, compression=compression,\n\u001b[0;32m-> 2593\u001b[0;31m                          protocol=protocol)\n\u001b[0m\u001b[1;32m   2594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2595\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto_clipboard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexcel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mto_pickle\u001b[0;34m(obj, path, compression, protocol)\u001b[0m\n\u001b[1;32m     71\u001b[0m     f, fh = _get_handle(path, 'wb',\n\u001b[1;32m     72\u001b[0m                         \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                         is_text=False)\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHIGHEST_PROTOCOL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;31m# ZIP Compression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mcompression\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'zip'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0mzf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m             \u001b[0;31m# Ensure the container is closed as well.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, **kwargs)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'wb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBytesZipFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64)\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1091\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'season_pickles/2010.pkl'"
     ]
    }
   ],
   "source": [
    "    for year in seasons.keys():\n",
    "        start_date = seasons[year]['start_date']\n",
    "        end_date = seasons[year]['end_date']\n",
    "        pull_clean_and_pickle(start_date, end_date, year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
